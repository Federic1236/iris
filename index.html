<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>iris</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background: #000;
            /* Rapid rainbow background */
            animation: rainbow 0.1s linear infinite;
        }

        @keyframes rainbow {
            0% { background: #ff0000; }
            25% { background: #00ff00; }
            50% { background: #0000ff; }
            75% { background: #ffff00; }
            100% { background: #ff0000; }
        }

        #bouncing-text {
            position: absolute;
            font-family: 'Impact', sans-serif;
            font-size: 10vw;
            color: white;
            text-shadow: 5px 5px 0px #000;
            white-space: nowrap;
            user-select: none;
            will-change: transform;
        }

        #start-screen {
            position: fixed;
            inset: 0;
            background: rgba(0,0,0,0.9);
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2rem;
            cursor: pointer;
            z-index: 999;
        }
    </style>
</head>
<body>

    <div id="start-screen">forza iris</div>
    <div id="bouncing-text">IRIS IRIS IRIS SIRI SIRI</div>

    <script>
        const text = document.getElementById('bouncing-text');
        const startScreen = document.getElementById('start-screen');
        
        // --- RELATIVE GITHUB PATH ---
        // If your file is in the same folder, just use the filename.
        // If it's in a folder called 'audio', use 'audio/music.mp3'
        const AUDIO_FILE = 'music.mp3'; 

        let audioCtx, source, delay, reverb, feedback;
        let x = 0, y = 0, dx = 10, dy = 10;

        async function init() {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            
            // Load audio from the repo relative path
            const response = await fetch(AUDIO_FILE);
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

            source = audioCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.loop = true;

            // Effect: Delay (Echo)
            delay = audioCtx.createDelay();
            delay.delayTime.value = 0.3;

            feedback = audioCtx.createGain();
            feedback.gain.value = 0.5;

            // Effect: Reverb
            reverb = audioCtx.createConvolver();
            reverb.buffer = createReverbBuffer(2.0);

            // Routing
            source.connect(reverb);
            reverb.connect(delay);
            delay.connect(feedback);
            feedback.connect(delay);
            
            source.connect(audioCtx.destination);
            delay.connect(audioCtx.destination);
            reverb.connect(audioCtx.destination);

            source.start();
            animate();
        }

        function createReverbBuffer(seconds) {
            const len = audioCtx.sampleRate * seconds;
            const buf = audioCtx.createBuffer(2, len, audioCtx.sampleRate);
            for (let i = 0; i < 2; i++) {
                let chan = buf.getChannelData(i);
                for (let j = 0; j < len; j++) {
                    chan[j] = (Math.random() * 2 - 1) * Math.pow(1 - j / len, 2);
                }
            }
            return buf;
        }

        function animate() {
            const maxX = window.innerWidth - text.offsetWidth;
            const maxY = window.innerHeight - text.offsetHeight;
            x += dx; y += dy;
            if (x >= maxX || x <= 0) dx *= -1;
            if (y >= maxY || y <= 0) dy *= -1;
            text.style.transform = `translate(${x}px, ${y}px)`;
            requestAnimationFrame(animate);
        }

        startScreen.addEventListener('click', () => {
            startScreen.remove();
            init();
        });
    </script>
</body>
</html>
